{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Using prior knowledge in order-based algorithms for causal discovery\n\nWe illustrate how to exploit prior knowledge and assumptions about the\ncausal structure that generates the data in the context of causal discovery with\norder-based algorithms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport networkx as nx\nfrom scipy import stats\nimport pandas as pd\nfrom pywhy_graphs.viz import draw\nfrom dodiscover import make_context\nfrom dodiscover.toporder.score import SCORE\nfrom dowhy import gcm\nfrom dowhy.gcm.util.general import set_random_seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulate some data\nFirst we will simulate data, starting from an Additive Noise Model (ANM).\nThis will then induce a causal graph, which we can visualize.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# set a random seed to make example reproducible\nseed = 12345\nrng = np.random.RandomState(seed=seed)\n\n\nclass MyCustomModel(gcm.PredictionModel):\n    def __init__(self, coefficient):\n        self.coefficient = coefficient\n\n    def fit(self, X, Y):\n        # Nothing to fit here, since we know the ground truth.\n        pass\n\n    def predict(self, X):\n        return self.coefficient * X\n\n    def clone(self):\n        # We don't really need this actually.\n        return MyCustomModel(self.coefficient)\n\n\n# set a random seed to make example reproducible\nset_random_seed(1234)\n\n# construct a causal graph that will result in\n# x -> y <- z -> w\nG = nx.DiGraph([(\"x\", \"y\"), (\"z\", \"y\"), (\"z\", \"w\")])\n\ncausal_model = gcm.ProbabilisticCausalModel(G)\ncausal_model.set_causal_mechanism(\"x\", gcm.ScipyDistribution(stats.binom, p=0.5, n=1))\ncausal_model.set_causal_mechanism(\"z\", gcm.ScipyDistribution(stats.binom, p=0.9, n=1))\ncausal_model.set_causal_mechanism(\n    \"y\",\n    gcm.AdditiveNoiseModel(\n        prediction_model=MyCustomModel(1),\n        noise_model=gcm.ScipyDistribution(stats.binom, p=0.8, n=1),\n    ),\n)\ncausal_model.set_causal_mechanism(\n    \"w\",\n    gcm.AdditiveNoiseModel(\n        prediction_model=MyCustomModel(1),\n        noise_model=gcm.ScipyDistribution(stats.binom, p=0.5, n=1),\n    ),\n)\n\n# Fit here would not really fit parameters, since we don't do anything in the fit method.\n# Here, we only need this to ensure that each FCM has the correct local hash (i.e., we\n# get an inconsistency error if we would modify the graph afterwards without updating\n# the FCMs). Having an empty data set is a small workaround, since all models are\n# pre-defined.\ngcm.fit(causal_model, pd.DataFrame(columns=[\"x\", \"y\", \"z\", \"w\"]))\n\n# sample the observational data\ndata = gcm.draw_samples(causal_model, num_samples=500)\n\nprint(data.head())\nprint(pd.Series({col: data[col].unique() for col in data}))\ndot_graph = draw(G)\ndot_graph.render(outfile=\"oracle_dag.png\", view=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the context with fixed edges\nDefine the context specifying the fixed directed edge (`z`, `y`) in the output graph.\nThis encodes prior domain information from the user, which specifies that there is\na directed connection between `z` and `y`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "included_edges = nx.DiGraph([(\"z\", \"y\")])\ncontext = make_context().variables(data=data).edges(include=included_edges).build()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run structure learning algorithm with fixed edges\nNow we run inference with the SCORE algorithm. The output of the inference\nmust be a graph including (`z`, `y`) in the set of edges.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "score = SCORE()  # or DAS() or NoGAM() or CAM()\nscore.learn_graph(data, context)\n\n# Verify that the output includes (`z`, `y`) in the set of edges.\ngraph = score.graph_\ndot_graph = draw(graph, name=\"DAG with (z, y) directed edge\")\ndot_graph.render(outfile=\"score_prior_include.png\", view=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the context with excluded edges\nThe context can also be used to encode prior information about directed edges that\nmust be excluded from the the output graph. In this example, we define the context\nthat excludes the edge (`z`, `w`) from the output DAG.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "excluded_edges = nx.DiGraph([(\"z\", \"w\")])\ncontext = make_context().variables(data=data).edges(exclude=excluded_edges).build()\n\n# Run structure learning algorithm with excluded edges\n# ----------------------------------------------------\n# Now we run inference with the SCORE algorithm. The edge (`z`, `w`)\n# must not appear in the output graph.\nscore = SCORE()  # or DAS() or NoGAM() or CAM()\nscore.learn_graph(data, context)\n\n# Verify that the output does not include (`z`, `w`) in the set of edges.\ngraph = score.graph_\ndot_graph = draw(graph, name=\"DAG without (z, w) directed edge\")\ndot_graph.render(outfile=\"score_prior_exclude.png\", view=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\nIn this tutorial we show how to encode prior knowledge about the solution with\nthe context object, in the setting of causal discovery with order-based algorithms.\nThis example can be generalized to the case of `NoGAM`, `DAS`, and `CAM` methods.\nFor a detailed example on order-based discovery approaches, see this\n`tutorial <ex-score-algorithm>`.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}